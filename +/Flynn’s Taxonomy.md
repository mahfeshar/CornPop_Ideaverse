---
up:
  - "[[Distributed Systems MOC]]"
related: 
created: 2024-11-12
---


## تصنيف Flynn لأنظمة الكمبيوتر:
تصنيف "Flynn’s Taxonomy" لأنظمة الكمبيوتر من حيث تدفق التعليمات والبيانات، واللي بيوضح الأنواع المختلفة للمعالجة، زي:

![[Pasted image 20241112070522.png]]
![[Pasted image 20241112070735.png]]
### 1. SISD (Single Instruction Stream, Single Data Stream):
![[Pasted image 20241112072200.png]]
- **التعريف**: النظام *بيمتلك معالج واحد CPU* 
 بياخد تعليمة واحدة Instruction ويعالج بيانات واحدة في الوقت نفسه.
- **مثال**: الحواسيب الشخصية التقليدية (مثل الحواسيب اللي تعتمد على معمارية von Neumann).
- **أداء العمليات**: النظام بيعالج التعليمة والبيانات بشكل متتابع، وبيتواصل المعالج مع الذاكرة عن طريق **Bus**.
- **القيود**: السرعة محدودة بسرعة الـ CPU و سرعة الـ Bus.
- **مثال على العمليات**: لو عايز تحسب مجموع N رقم، المعالج هيحتاج يقرأ الأرقام من الذاكرة في **N خطوة متتابعة**، ويجمعهم في N-1 خطوة.
- **تحسين الأداء**: لتحقيق أداء أعلى، يمكن للنظام استخدام أساليب مثل **multiprogramming** (تنفيذ عدة برامج في وقت واحد بتقسيم وقت المعالج بينهم)، أو تنفيذ عمليات **I/O** بالتزامن مع البرنامج الرئيسي.
- **طرق التحسين**:
    1. **التنفيذ المتزامن لعدة برامج**: النظام بيقسم وقت المعالج بين البرامج المختلفة (زي نظام **Round Robin** لتقسيم الوقت).
    2. **تنفيذ عمليات الإدخال والإخراج بشكل متزامن** مع البرنامج الرئيسي.
    3. استخدام Parallel functional units داخل وحدة المعالجة، حيث يتم تخصيص وظيفة لكل وحدة.
    4. الـ**Pipelining**: تقسم التعليمة إلى مراحل متعددة، وكل مرحلة تنفذ في معالج منفصل، مثل: **fetching، decoding، operand fetch، ALU execution**.


### 2. SIMD (Single Instruction Stream, Multiple Data Stream):
![[Pasted image 20241112072247.png]]
- **التعريف**: بيقوم بإصدار تعليمة واحدة بتتنفذ على بيانات متعددة، عنده *عدة معالجات* تعمل على بيانات مختلفة في نفس الوقت.
- **التحكم**: بيتم التحكم بواسطة وحدة تحكم مركزية **Central Control Unit** تصدر نفس التعليمة لكل معالج.
- **التزامن**: المعالجات بتشتغل بتزامن كامل synchronously باستخدام **Global Clock**، بحيث كل خطوة تنفيذية بتتم في نفس اللحظة على كل معالج لكن على بيانات مختلفة.
- **استخداماته**: الأفضل في التطبيقات اللي بتحتاج عمليات على مصفوفات matrices أو متجهات vectors.
- **مثال عملي**: لو عندك مصفوفتين A و B وعايز تجمعهم في مصفوفة C، بتقسم العمل على أربع معالجات، وكل معالج بيجمع عناصر معينة في نفس الوقت، وده بيقلل زمن التنفيذ إلى خطوة واحدة بدل أربع خطوات.
- **التحكم في تفعيل المعالجات**: في بعض الأحيان، ممكن تحتاج تشغل عدد معين من المعالجات فقط لتنفيذ تعليمة معينة، والتعليمات بتحدد أي المعالجات **تعمل** وأيها **ينتظر**.
- **التواصل بين المعالجات**: ضروري في بعض التطبيقات إن المعالجات تتواصل مع بعضها، وده ممكن يحصل بطريقتين:
    1. **Shared Memory** (ذاكرة مشتركة).
    2. **Interconnection Network** (شبكة تواصل) تستخدم الرسائل لنقل البيانات.
#### GPU and SIMD
نعم، يمكن اعتبار الـ **GPU** (وحدة معالجة الرسوميات) كنوع من **SIMD** (Single Instruction, Multiple Data) إلى حد كبير، لأنهما بيستخدمان نفس الفكرة الأساسية:

##### كيف يعمل الـ SIMD والـ GPU؟
- في **SIMD**، النظام بيصدر تعليمة واحدة لكن يطبقها على بيانات متعددة في نفس الوقت. بمعنى أن كل المعالجات بتنفيذ نفس العملية على مجموعات مختلفة من البيانات.
- الـ**GPU** بيستخدم نفس المبدأ. بيتم برمجة الـ GPU بحيث يقوم بتنفيذ نفس التعليمة على بيانات متعددة، مثل معالجة بكسلات الصورة أو تطبيق مؤثر معين على مجموعة من العناصر في نفس الوقت.

##### لماذا يُعتبر الـ GPU مناسبًا للـ SIMD؟
- **التوازي الواسع**: يحتوي الـ GPU على مئات أو آلاف من الأنوية الصغيرة المصممة للعمل في توازي على بيانات مختلفة. ده بيخليه ممتاز للتطبيقات اللي بتحتاج نفس العملية على بيانات متعددة (زي الرسومات، والتعلم العميق، ومعالجة الصور).
- **التزامن**: كل نواة بتشتغل في تزامن مع باقي الأنوية، وكلها بتنفذ نفس التعليمات على بيانات مختلفة، وده جوهر الـ SIMD.

##### مثال عملي:
تخيل إنك بتعالج صورة باستخدام **GPU**، وعايز تزود درجة السطوع لكل بكسل. هنا الـ GPU بيطبق نفس التعليمة (زيادة السطوع) على كل بكسل في الصورة، وكل نواة بتشتغل على بكسل مختلف. ده بيسمح بمعالجة الصورة كلها بشكل أسرع بكتير من المعالجة المتتابعة.

##### الفرق بين الـ GPU و SIMD التقليدي:
- في **SIMD التقليدي** (زي المعالجات المتجهية)، كل وحدة معالجة بتطبق التعليمة على جزء محدد من البيانات تحت سيطرة وحدة تحكم مركزية.
- في **GPU**، الأنوية نفسها بتعمل كأنها وحدات معالجة مستقلة نوعًا ما، وبتنفذ نفس التعليمة على بيانات مختلفة لكن بتتشارك بعض الموارد زي الذاكرة.

##### ملخص:
الـ **GPU** بيستخدم بنية قريبة جدًا من **SIMD**، حيث بيقوم بتنفيذ نفس العملية على بيانات متعددة في وقت واحد، وده بيخليه مناسب جدًا للعمليات المتوازية زي معالجة الرسومات وحسابات التعلم العميق.
### 3. MISD (Multiple Instruction Stream, Single Data Stream):
![[Pasted image 20241112074852.png]]
- **التعريف**: النظام بياخد تعليميات متعددة على نفس البيانات.
- **أداء العمليات**: كل معالج بياخد تعليمة مختلفة ويطبقها على نفس البيانات.
- **الاستخدامات**: 
     النظام ده نادر الاستخدام في التطبيقات التجارية، لأن معظم التطبيقات بتحتاج أنظمة بتتعامل مع بيانات متعددة. 
     لكنه مفيد في بعض الحالات الخاصة زي تحليل البيانات المتتالي computations.
- **مثال عملي**: فحص عدد معين (مثل Z) إذا كان عددًا أوليًا، ممكن استخدام عدة معالجات، وكل معالج يحاول يقسم العدد Z على رقم مختلف في نفس الوقت، للتأكد من أوليته.
- **التطبيقات المحتملة**: في العادة بيستخدم في الأنظمة اللي بتحتاج إجراء سلسلة من العمليات المتتالية على نفس البيانات، مثل معالجة الإشارات أو بعض أنظمة التحكم.

#### Pipelining
![[Pasted image 20241112075158.png]]
- **التعريف**: هي تقنية لتقسيم عملية كبيرة ومعقدة إلى سلسلة من الخطوات الصغيرة (مراحل) بحيث يتم تنفيذ كل خطوة على معالج منفصل. يتم تمرير البيانات من مرحلة إلى مرحلة كما في خط الإنتاج (Assembly Line).

- **كيف يعمل pipelining**: يتم تقسيم التعليمة أو العملية إلى عدة مراحل (مثل **fetching, decoding, execution**)، وكل مرحلة يتم تنفيذها في وحدة معالجة مستقلة. بعد انتهاء مرحلة، تنتقل النتائج إلى المرحلة التالية.

- **التطبيق في MISD**:
    - في نظام **MISD**، يتم تنفيذ نفس البيانات عبر مراحل متعددة من التعليمات المتتابعة، بحيث كل مرحلة تنفذ تعليمة معينة على البيانات وتُمرر النتائج للمرحلة التالية.
    - يُستخدم غالبًا في التطبيقات اللي تتطلب معالجة معقدة ومتتالية، زي بعض أنواع التحليل الهندسي أو معالجة الإشارات.
- **مثال عملي**:
    - تخيل Pipeline لمعالجة الإشارات الصوتية، حيث تمر الإشارة عبر سلسلة من الوحدات (كل وحدة تنفذ معالجة مختلفة على نفس الإشارة). يمكن أن تكون المراحل: **تصفية الضوضاء، تعديل الصوت، تضخيم الإشارة**، وهكذا.
    - البيانات (الإشارة الصوتية) تمر من مرحلة إلى أخرى، وكل مرحلة تضيف نوعًا من المعالجة.
- **فوائد pipelining في MISD**:
    - يسمح بتنفيذ العمليات الكبيرة بشكل أسرع لأن كل مرحلة تشتغل بالتوازي على بيانات مختلفة، بحيث تكون كل مرحلة مشغولة دائمًا.
    - يعزز **الكفاءة** باستخدام الموارد بشكل مستمر بدل من الانتظار حتى تنتهي العملية كاملةً.
### 4. MIMD (Multiple Instruction Stream, Multiple Data Stream):
![[Pasted image 20241112075746.png]]
- **التعريف**: النظام يمتلك عدة معالجات، وكل معالج ممكن يشغل تعليمة مختلفة على بيانات مختلفة.
- **التزامن**: المعالجات بتشتغل بشكل غير متزامن **(Asynchronously)**، بحيث كل معالج بيقدر يعمل عملية مختلفة على بيانات مختلفة في نفس الوقت.
- **الاستخدامات**: النوع ده هو الأكثر عمومية والأكثر قوة من الأنواع الأخرى، ويستخدم في الأنظمة المتوازية والموزعة، زي الأنظمة السحابية (Cloud)، وأنظمة الـ Grid، وأنظمة الكلاستر (Cluster).

![[Pasted image 20241112080045.png]]

ممكن نبقا موجودين Physically مع بعض بشكل حقيقي ونبقا Logically بنعمل نفس الحاجة مثلًا، فكدا عندنا أربع أنواع مختلفة على حسب الإتنين دول

- **التصنيفات الداخلية**:
    - الـ**Tightly Coupled Systems (أنظمة مرتبطة بشدة)**: دي أنظمة بتتكون من عدة معالجات قريبة من بعضها، وبتتشارك ذاكرة مشتركة *shared memory*، زي أنظمة **multiprocessors**. بيتم التحكم فيها عن طريق نظام تشغيل واحد، وأمثلة عليها: **ENCORE، MULTIMAX، SEQUENT**.
    ![[Pasted image 20241112081537.png]]

    - الـ**Loosely Coupled Systems (أنظمة مرتبطة بضعف)**: معالجات بتتواصل عبر شبكة *interconnection network* وتستخدم ذاكرة موزعة، زي أنظمة **multicomputer**. أمثلة عليها: **grid systems، clusters**، واللي غالبًا تُعتبر نظم موزعة.
    ![[Pasted image 20241112082558.png]]
    ![[Pasted image 20241112081633.png]]
    - **Multicomputer** is sometimes referred to as distributed systems and sometimes not.